import networkx as nx
from scipy.sparse import coo_matrix, csr_matrix, bmat, kron
from numpy import ones, zeros, identity
from numpy.linalg import inv
import bisect
import networkx


def trip_centrality(edge_list, alpha, epsilon=None):
    alpha_tilde = alpha ** (1 / 2)
    if len(edge_list[0]) == 4:
        # only 1 layer
        primary_nodes = []
        times = []
        n_secondary = len(edge_list)
        rows = []
        columns = []
        count = 2 * n_secondary
        for e in edge_list:
            if e[0] not in primary_nodes:
                primary_nodes.append(e[0])
            if e[1] not in primary_nodes:
                primary_nodes.append(e[1])
            if e[2] not in times:
                bisect.insort(times, e[2])
                rows.append([])
                columns.append([])
            if e[3] not in times:
                bisect.insort(times, e[3])
                rows.append([])
                columns.append([])
            rows[times.index(e[2])].append(primary_nodes.index(e[0]))
            columns[times.index(e[2])].append(count)
            rows[times.index(e[3])].append(count)
            columns[times.index(e[3])].append(primary_nodes.index(e[1]))
            count = count + 1
        adjacency = []
        n_primary = len(primary_nodes)
        centrality = ones(n_primary + n_secondary)
        for t in times:
            A_t = csr_matrix((ones(len(rows[times.index(t)])), (rows[times.index(t)], columns[times.index(t)])),
                             shape=(3 * n_secondary, 3 * n_secondary), dtype=int)
            A12_t = A_t[:n_primary, 2 * n_secondary:]
            A21_t = A_t[2 * n_secondary:, :n_primary]
            A_t = bmat([[None, A21_t], [A12_t, None]], format='csr')
            centrality = alpha_tilde * A_t.dot(centrality) + centrality
        centrality = centrality - ones(n_primary + n_secondary)  # TODO add dictionary
        centrality = dict(zip(primary_nodes, centrality))
    if len(edge_list[0]) == 5:  # multiple layers
        primary_nodes = []
        times = []
        n_secondary = len(edge_list)
        rows = []
        columns = []
        layers = []
        for e in edge_list:
            primary_nodes.append(e[0])
            primary_nodes.append(e[1])
            bisect.insort(times, e[2])  # TODO understand if it is better to add every time and then sort or in this way
            bisect.insort(times, e[3])
            layers.append(e[4])
        primary_nodes = list(set(primary_nodes))
        n_primary = len(primary_nodes)
        times = list(set(times))
        n_times = len(times)
        layers = list(set(layers))
        n_layers = len(layers)
        n_nodes = n_primary * n_layers + n_secondary
        matrices_data = []
        for i in range(n_times):
            matrices_data.append([[], []])
        edge_count = 0
        for e in edge_list:
            matrices_data[times.index(e[2])][0].append(n_primary * layers.index(e[4]) + primary_nodes.index(e[0]))
            matrices_data[times.index(e[2])][1].append(n_primary * n_layers + edge_count)
            matrices_data[times.index(e[3])][0].append(n_primary * n_layers + edge_count)
            matrices_data[times.index(e[3])][1].append(n_primary * layers.index(e[4]) + primary_nodes.index(e[1]))
            edge_count = edge_count + 1
        matrices = []
        if epsilon is not None:
            K_small = ones((n_layers, n_layers)) * epsilon + identity(n_layers) * (1 - epsilon)
            I_primary = identity(n_primary)
            K_big = kron(K_small, I_primary)
            K = bmat([[K_big, None], [None, identity(n_secondary)]], format='csr')
        centrality = ones(n_nodes)
        auxiliary = centrality
        # solving K^-1*e is equal to divide the first n_primary*n_layers elements by 1+(n_layers-1)*epsilon
        auxiliary[0: n_primary * n_layers] = auxiliary[0: n_primary * n_layers] / (1 + epsilon * (n_layers - 1))
        data = matrices_data[-1]
        # creating last matrix to compute (I+alpha_tilde A)*(K^-1)e
        matrix = csr_matrix((ones(len(data[0])), (data[0], data[1])), shape=(n_nodes, n_nodes), dtype=int)
        centrality = auxiliary + alpha_tilde * (matrix.dot(centrality))
        for data in matrices_data[n_times - 2::-1]:
            #  (I+alpha_tilde AK)*centrality
            matrix = csr_matrix((ones(len(data[0])), (data[0], data[1])), shape=(n_nodes, n_nodes), dtype=int)
            centrality = centrality + alpha_tilde * matrix.dot(K.dot(centrality))  # TODO valutare ottimizzazione
        aggregated_centrality = zeros(n_primary)
        for i in range(n_primary):
            aggregated_centrality = aggregated_centrality + centrality[i:n_primary + i]
        centrality = dict(zip(primary_nodes, aggregated_centrality))
    return centrality


def betweenness_index(n_nodes, n_times, n_layers, node_index, time_index, layer_index):
    index = n_nodes * n_times * layer_index + n_nodes * time_index + node_index
    return index


def betweenness_centrality(edge_list, delta_t, alpha, epsilon):
    # TODO input: edge_list with [departure_node, arrival_node, departure_time, arrival_time, layer] as rows

    n_edges = len(edge_list)
    times = []
    nodes = []
    layers = []
    node_layer_time_dict = {}
    for e in edge_list:
        nodes.append(e[0])
        nodes.append(e[1])
        times.append(e[2])
        times.append(e[3])
        layers.append(e[4])
        node_layer_time_dict[e[0]] = {e[4]: {e[2]: {e[3]: e[1]}}}  # departure: layer: time 1: time 2: arrival
    nodes = list(set(nodes))
    n_nodes = len(nodes)
    t_min = min(set(times))
    t_max = max(set(times))
    times = list(range(t_min, t_max+delta_t, delta_t))
    n_times = len(times)
    layers = list(set(layers))
    n_layers = len(layers)
    static_edges = []
    for e in edge_list:
        node_index_1 = nodes.index(e[0])
        time_index_1 = times.index(e[2])
        layer_index_1 = layers.index(e[4])
        row_index = betweenness_index(n_nodes, n_times, n_layers, node_index_1, time_index_1, layer_index_1)
        node_index_2 = nodes.index(e[1])
        time_index_2 = times.index(e[3])
        layer_index_2 = layer_index_1
        column_index = betweenness_index(n_nodes, n_times, n_layers, node_index_2, time_index_2, layer_index_2)
        weight_index = alpha + (1 - alpha) * (time_index_2 - time_index_1)
        static_edges.append((row_index, column_index, weight_index))
        for layer in layers:
            t = None
            temp = None
            if e[1] in node_layer_time_dict.keys():
                if layer in node_layer_time_dict[e[1]].keys():
                    temp = node_layer_time_dict[e[1]][layer]
                    t = [s for s in temp.keys() if s > e[3]]
                    if t:  # if t is neither the empty sequence nor None
                        t = min(t)

                        # create switching links

                        row_switch_idx = row_index
                        node_switch_idx_2 = node_index_2
                        time_switch_idx_2 = time_index_2
                        layer_switch_idx_2 = layers.index(layer)
                        column_switch_idx = betweenness_index(n_nodes, n_times, n_layers, node_switch_idx_2,
                                                              time_switch_idx_2, layer_switch_idx_2)
                        weight_switch_idx = alpha * epsilon
                        static_edges.append((row_switch_idx, column_switch_idx, weight_switch_idx))

                        # create waiting links

                        time_waiting_idx_1 = time_switch_idx_2
                        row_waiting_idx = column_switch_idx
                        node_waiting_idx_2 = node_switch_idx_2
                        time_waiting_idx_2 = times.index(t)
                        layer_waiting_idx_2 = layer_switch_idx_2
                        column_waiting_idx = betweenness_index(n_nodes, n_times, n_layers, node_switch_idx_2,
                                                               time_switch_idx_2, layer_switch_idx_2)
                        weight_waiting_idx = time_waiting_idx_2 - time_waiting_idx_1
                        static_edges.append((row_waiting_idx, column_waiting_idx, weight_waiting_idx))
    # create static network
    G = nx.DiGraph()
    G.add_weighted_edges_from(static_edges)
    print(G.edges)
    return G


edges = [[1, 2, 3, 4, 'lambda'], [2, 1, 3, 4, 'mu'], [1, 2, 4, 5, 'lambda'], [1, 2, 7, 8, 'lambda'], [2, 1, 5, 6, 'mu']]
# print(trip_centrality(edges, 0.5, 0.3))
betweenness_centrality(edges, 1, 0.5, 0.3)
# if len(edge_list[0]==5): # multiple layers

"""

departure_times = [e[2] for e in edge_list]
arrival_times = [e[3] for e in edge_list]
t_min = min(departure_times)
t_max = max(arrival_times)
time_frames = range(t_min, t_max, frame_time)
number_of_edges = len(edge_list)
primary_nodes = []
secondary_nodes = []
row = []
col = []
for e in edge_list:
    if e[0] not in primary_nodes:
        primary_nodes.append(e[0])
    if e[1] not in primary_nodes:
        primary_nodes.append(e[1])
    secondary_nodes.append((e[0], e[1]))
if frame_time is None:
    flights_duration = [t[3]-t[2] for t in edge_list]
    frame_time = min(flights_duration)/2
"""
